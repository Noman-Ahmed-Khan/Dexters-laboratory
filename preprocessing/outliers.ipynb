{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers\n",
    "1. Univariate Outlier\n",
    "2. Multivariate Outlier\n",
    "3. Global Outlier\n",
    "4. Point Outlier\n",
    "5. local Outlier\n",
    "6. Contextual Outlier\n",
    "7. Collective Outlier\n",
    "8. Recurrent Outlier\n",
    "9. Periodic Outlier\n",
    "\n",
    "---------------------------------------------------\n",
    "For each method, choose based on:               \n",
    "\n",
    "- Data distribution (normal vs. skewed).        \n",
    "\n",
    "- Dimensionality (univariate vs. multivariate). \n",
    "\n",
    "- Dataset size (small, medium, large).           \n",
    "\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m zscore\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(zscore)\n\u001b[0;32m      6\u001b[0m outliers \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mabs\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_score\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m threshold]  \u001b[38;5;66;03m# e.g., threshold = 3\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# **When to Use**:  \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# - Use when the data is normally distributed.  \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# - Detects points far from the mean in terms of standard deviation.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "### 1. **Z-Score**\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "\n",
    "df['z_score'] = df['column_name'].apply(zscore)\n",
    "outliers = df[abs(df['z_score']) > threshold]  # e.g., threshold = 3\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Use when the data is normally distributed.  \n",
    "# - Detects points far from the mean in terms of standard deviation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 2. **Interquartile Range (IQR)**\n",
    "\n",
    "Q1 = df['column_name'].quantile(0.25)\n",
    "Q3 = df['column_name'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['column_name'] < lower_bound) | (df['column_name'] > upper_bound)]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Use for skewed data.  \n",
    "# - Non-parametric method, not reliant on data distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "model = DBSCAN(eps=0.5, min_samples=5)\n",
    "df['dbscan_labels'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['dbscan_labels'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For spatial or clustering-based outliers.  \n",
    "# - Works well when clusters are dense and outliers are isolated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. **Isolation Forest**\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "model = IsolationForest(contamination=0.1)\n",
    "df['anomaly_score'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['anomaly_score'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Effective for high-dimensional datasets.  \n",
    "# - Isolation-based method, identifies anomalies as points that are easily isolated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. **Local Outlier Factor (LOF)**\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "model = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "df['lof_scores'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['lof_scores'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Detects local anomalies in clusters.  \n",
    "# - Suitable for datasets with varying densities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 6. **Elliptic Envelope**\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "model = EllipticEnvelope(contamination=0.1)\n",
    "model.fit(df[['column_x', 'column_y']])\n",
    "df['elliptic_env'] = model.predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['elliptic_env'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For Gaussian distributed data.  \n",
    "# - Models data using covariance to detect deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. **One-Class SVM**\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "model = OneClassSVM(kernel='rbf', nu=0.1, gamma=0.1)\n",
    "df['svm_scores'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['svm_scores'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Good for nonlinear relationships.  \n",
    "# - Models normal data points and identifies those that deviate significantly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8. **Mahalanobis Distance**\n",
    "import numpy as np\n",
    "\n",
    "cov_matrix = np.cov(df[['column_x', 'column_y']].values, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "mean = df[['column_x', 'column_y']].mean(axis=0)\n",
    "df['mahalanobis'] = df[['column_x', 'column_y']].apply(\n",
    "    lambda row: np.sqrt((row - mean).T @ inv_cov_matrix @ (row - mean)),\n",
    "    axis=1\n",
    ")\n",
    "outliers = df[df['mahalanobis'] > threshold]  # e.g., threshold = 3\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For multidimensional Gaussian distributions.  \n",
    "# - Measures the distance from the mean using covariance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9. **Robust Random Cut Forest**\n",
    "# Requires third-party libraries like Amazon's `sagemaker`.\n",
    "from sagemaker import RandomCutForest\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Handles streaming data and multidimensional data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10. **Histogram-based Outlier Score (HBOS)**\n",
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "model = HBOS()\n",
    "model.fit(df[['column_x', 'column_y']])\n",
    "df['hbos_scores'] = model.decision_function(df[['column_x', 'column_y']])\n",
    "outliers = df[model.predict(df[['column_x', 'column_y']]) == 1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Efficient for large datasets.  \n",
    "# - Non-parametric, based on histograms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 11. **K-Nearest Neighbors (KNN)**\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=5)\n",
    "knn.fit(df[['column_x', 'column_y']])\n",
    "distances, indices = knn.kneighbors(df[['column_x', 'column_y']])\n",
    "df['knn_outlier_score'] = distances.mean(axis=1)\n",
    "outliers = df[df['knn_outlier_score'] > threshold]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For detecting distance-based outliers.  \n",
    "# - Good for small to medium-sized datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 12. **K-Means Clustering**\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "df['kmeans_labels'] = kmeans.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['kmeans_labels'] == anomaly_cluster]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Outliers are farthest from cluster centroids.  \n",
    "# - Works well with clusterable datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 13. **Local Correlation Integral (LOCI)**\n",
    "# Requires custom implementation or specialized libraries.\n",
    "# Pseudo-code, depends on specific library\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Detects outliers based on local density correlations.  \n",
    "# - Suitable for datasets with varying densities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
