{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers\n",
    "1. Univariate Outlier\n",
    "2. Multivariate Outlier\n",
    "3. Global Outlier\n",
    "4. Point Outlier\n",
    "5. local Outlier\n",
    "6. Contextual Outlier\n",
    "7. Collective Outlier\n",
    "8. Recurrent Outlier\n",
    "9. Periodic Outlier\n",
    "\n",
    "---------------------------------------------------\n",
    "For each method, choose based on:               \n",
    "\n",
    "- Data distribution (normal vs. skewed).        \n",
    "\n",
    "- Dimensionality (univariate vs. multivariate). \n",
    "\n",
    "- Dataset size (small, medium, large).           \n",
    "\n",
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m zscore\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_score\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(zscore)\n\u001b[0;32m      6\u001b[0m outliers \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;28mabs\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mz_score\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m threshold]  \u001b[38;5;66;03m# e.g., threshold = 3\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# **When to Use**:  \u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# - Use when the data is normally distributed.  \u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# - Detects points far from the mean in terms of standard deviation.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "### 1. **Z-Score**\n",
    "from scipy.stats import zscore\n",
    "import pandas as pd\n",
    "\n",
    "df['z_score'] = df['column_name'].apply(zscore)\n",
    "outliers = df[abs(df['z_score']) > threshold]  # e.g., threshold = 3\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Use when the data is normally distributed.  \n",
    "# - Detects points far from the mean in terms of standard deviation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 2. **Interquartile Range (IQR)**\n",
    "\n",
    "Q1 = df['column_name'].quantile(0.25)\n",
    "Q3 = df['column_name'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "outliers = df[(df['column_name'] < lower_bound) | (df['column_name'] > upper_bound)]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Use for skewed data.  \n",
    "# - Non-parametric method, not reliant on data distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 3. **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "model = DBSCAN(eps=0.5, min_samples=5)\n",
    "df['dbscan_labels'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['dbscan_labels'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For spatial or clustering-based outliers.  \n",
    "# - Works well when clusters are dense and outliers are isolated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. **Isolation Forest**\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "model = IsolationForest(contamination=0.1)\n",
    "df['anomaly_score'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['anomaly_score'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Effective for high-dimensional datasets.  \n",
    "# - Isolation-based method, identifies anomalies as points that are easily isolated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. **Local Outlier Factor (LOF)**\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "model = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "df['lof_scores'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['lof_scores'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Detects local anomalies in clusters.  \n",
    "# - Suitable for datasets with varying densities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 6. **Elliptic Envelope**\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "model = EllipticEnvelope(contamination=0.1)\n",
    "model.fit(df[['column_x', 'column_y']])\n",
    "df['elliptic_env'] = model.predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['elliptic_env'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For Gaussian distributed data.  \n",
    "# - Models data using covariance to detect deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 7. **One-Class SVM**\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "model = OneClassSVM(kernel='rbf', nu=0.1, gamma=0.1)\n",
    "df['svm_scores'] = model.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['svm_scores'] == -1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Good for nonlinear relationships.  \n",
    "# - Models normal data points and identifies those that deviate significantly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 8. **Mahalanobis Distance**\n",
    "import numpy as np\n",
    "\n",
    "cov_matrix = np.cov(df[['column_x', 'column_y']].values, rowvar=False)\n",
    "inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "mean = df[['column_x', 'column_y']].mean(axis=0)\n",
    "df['mahalanobis'] = df[['column_x', 'column_y']].apply(\n",
    "    lambda row: np.sqrt((row - mean).T @ inv_cov_matrix @ (row - mean)),\n",
    "    axis=1\n",
    ")\n",
    "outliers = df[df['mahalanobis'] > threshold]  # e.g., threshold = 3\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For multidimensional Gaussian distributions.  \n",
    "# - Measures the distance from the mean using covariance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 9. **Robust Random Cut Forest**\n",
    "# Requires third-party libraries like Amazon's `sagemaker`.\n",
    "from sagemaker import RandomCutForest\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Handles streaming data and multidimensional data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 10. **Histogram-based Outlier Score (HBOS)**\n",
    "from pyod.models.hbos import HBOS\n",
    "\n",
    "model = HBOS()\n",
    "model.fit(df[['column_x', 'column_y']])\n",
    "df['hbos_scores'] = model.decision_function(df[['column_x', 'column_y']])\n",
    "outliers = df[model.predict(df[['column_x', 'column_y']]) == 1]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Efficient for large datasets.  \n",
    "# - Non-parametric, based on histograms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 11. **K-Nearest Neighbors (KNN)**\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=5)\n",
    "knn.fit(df[['column_x', 'column_y']])\n",
    "distances, indices = knn.kneighbors(df[['column_x', 'column_y']])\n",
    "df['knn_outlier_score'] = distances.mean(axis=1)\n",
    "outliers = df[df['knn_outlier_score'] > threshold]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - For detecting distance-based outliers.  \n",
    "# - Good for small to medium-sized datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 12. **K-Means Clustering**\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "df['kmeans_labels'] = kmeans.fit_predict(df[['column_x', 'column_y']])\n",
    "outliers = df[df['kmeans_labels'] == anomaly_cluster]\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Outliers are farthest from cluster centroids.  \n",
    "# - Works well with clusterable datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 13. **Local Correlation Integral (LOCI)**\n",
    "# Requires custom implementation or specialized libraries.\n",
    "# Pseudo-code, depends on specific library\n",
    "\n",
    "# **When to Use**:  \n",
    "# - Detects outliers based on local density correlations.  \n",
    "# - Suitable for datasets with varying densities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In **Seaborn**, you can visually check for outliers using various types of plots. Below are some common methods to detect outliers in your data:\n",
    "\n",
    "### 1. **Boxplot** (Most Common Method)\n",
    "A **boxplot** is a great tool to visually detect outliers. It displays the distribution of data through **quartiles** and shows any data points that fall outside the whiskers as potential outliers.\n",
    "\n",
    "#### Code Example:\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "sns.set(style=\"whitegrid\")\n",
    "data = sns.load_dataset(\"tips\")  # Example dataset\n",
    "\n",
    "# Boxplot for visualizing outliers in the 'total_bill' column\n",
    "sns.boxplot(x=data['total_bill'])\n",
    "plt.title('Boxplot for Total Bill')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### How to Interpret:\n",
    "- **Whiskers**: The lines extending from the box represent the range within 1.5 times the **interquartile range (IQR)** from the 1st and 3rd quartiles.\n",
    "- **Outliers**: Points outside of the whiskers are considered outliers and are plotted individually.\n",
    "\n",
    "### 2. **Violin Plot**\n",
    "A **violin plot** combines aspects of boxplot and density plot, providing a deeper understanding of the distribution. Itâ€™s helpful for detecting outliers in continuous data.\n",
    "\n",
    "#### Code Example:\n",
    "```python\n",
    "# Violin plot for visualizing outliers in the 'total_bill' column\n",
    "sns.violinplot(x=data['total_bill'])\n",
    "plt.title('Violin Plot for Total Bill')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### How to Interpret:\n",
    "- The width of the violin at various values indicates the density of the data. Outliers might appear as points outside the main body of the violin.\n",
    "\n",
    "### 3. **Scatter Plot**\n",
    "For two or more continuous variables, a **scatter plot** can be helpful for identifying outliers that may appear far away from the rest of the data points.\n",
    "\n",
    "#### Code Example:\n",
    "```python\n",
    "# Scatter plot for visualizing outliers in the 'total_bill' vs 'tip' columns\n",
    "sns.scatterplot(x=data['total_bill'], y=data['tip'])\n",
    "plt.title('Scatter Plot of Total Bill vs Tip')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### How to Interpret:\n",
    "- Outliers will appear as points far away from the majority of data points in the plot.\n",
    "\n",
    "### 4. **Pairplot**\n",
    "If you want to visualize the relationships between multiple variables and identify potential outliers in a pairwise manner, you can use **pairplot**.\n",
    "\n",
    "#### Code Example:\n",
    "```python\n",
    "# Pairplot for visualizing relationships between multiple columns\n",
    "sns.pairplot(data[['total_bill', 'tip', 'size']])\n",
    "plt.title('Pairplot for Total Bill, Tip, and Size')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### How to Interpret:\n",
    "- The diagonal shows the univariate distribution (with histograms), and the off-diagonal plots show relationships between pairs of variables.\n",
    "- Outliers will appear as points far away from the general trend in any of the scatter plots.\n",
    "\n",
    "### 5. **Swarm Plot**\n",
    "A **swarm plot** is another method for visualizing data points, where individual data points are plotted in a way that avoids overlap. This can help you see if there are any outliers in categorical or continuous data.\n",
    "\n",
    "#### Code Example:\n",
    "```python\n",
    "# Swarm plot for visualizing outliers in the 'total_bill' column by 'time' category\n",
    "sns.swarmplot(x='time', y='total_bill', data=data)\n",
    "plt.title('Swarm Plot for Total Bill by Time')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### How to Interpret:\n",
    "- Outliers are displayed as points that are far away from the others on the plot.\n",
    "\n",
    "### 6. **Histogram**\n",
    "A **histogram** shows the frequency distribution of the data. While not specifically designed for outlier detection, it can give you an idea of whether data is spread across a large range, potentially indicating outliers.\n",
    "\n",
    "#### Code Example:\n",
    "```python\n",
    "# Histogram for visualizing the distribution of the 'total_bill' column\n",
    "sns.histplot(data['total_bill'], kde=True)\n",
    "plt.title('Histogram for Total Bill')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### How to Interpret:\n",
    "- Outliers could appear as bars far from the rest of the data distribution.\n",
    "\n",
    "### Summary of Methods:\n",
    "- **Boxplot**: Shows the distribution, quartiles, and potential outliers as points outside the whiskers.\n",
    "- **Violin Plot**: Combines boxplot and density plot, providing more detailed information about the distribution.\n",
    "- **Scatter Plot**: Helps visualize relationships between two continuous variables and detect points that are far from the rest.\n",
    "- **Pairplot**: For visualizing pairwise relationships between multiple variables, useful for detecting outliers in multi-dimensional data.\n",
    "- **Swarm Plot**: Helps visualize individual data points in categorical data to detect outliers.\n",
    "- **Histogram**: Useful for understanding the distribution and spotting outliers in a univariate dataset.\n",
    "\n",
    "These visualizations can help you identify and confirm outliers before deciding on how to handle them (e.g., removing or transforming the outliers)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
